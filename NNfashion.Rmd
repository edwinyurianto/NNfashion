---
title: "Untitled"
output: html_document
---

first, We read the data 
```{r}
fashion_train <- read.csv("data_input/fashionmnist/train.csv")
fashion_test <- read.csv("data_input/fashionmnist/test.csv")
```

make a table to check the labels of the train data.

```{r}
table(fashion_train[,"label"])
```

the distribution of our class labels do seem to be spread out evenly. 

now, we can try to see the first image by converting the first row of the data into a matrix.(the image is 28 x 28)
```{r}
f1 <- matrix(fashion_train[1,2:ncol(fashion_train)], nrow=28, ncol=28)
f1 <- apply(f1, 2, as.numeric)
f1 <- apply(f1, 2, rev)
```
```{r}
image(f1)
```

```{r}
categories <- c("T-shirt", "Trouser", "Pullover", "Dress", 
    "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Boot")
```

This is the categories for each number on the labels, now we can check the label of the image above.

```{r}
head(fashion_train[2,1])
```
label 2 means it's a pullover.(the labels starts from 0 to 9)

```{r}
image(1:28, 1:28, f1)
text(3, 2, col="white", cex=1.2, categories[fashion_train[1, 1]+1])
```

we need to check the range of the value for each pixel(each column represent a pixel of an image.).
```{r}
range(fashion_train[1,2:ncol(fashion_train)])
```

now we can visualized the image by using a function and turn the image into grayscale image (grey.colors(255)) instead of the default heatmap (heat.colors(12)).
```{r}
vizTrain <- function(input){
  
  dimmax <- sqrt(ncol(fashion_train[,-1]))
  
  dimn <- ceiling(sqrt(nrow(input)))
  par(mfrow=c(dimn, dimn), mar=c(.1, .1, .1, .1))
  
  for (i in 1:nrow(input)){
      f1 <- matrix(input[i,2:ncol(input)], nrow=dimmax, byrow=T)
      f1 <- apply(f1, 2, as.numeric)
      f1 <- t(apply(f1, 2, rev))
      
      image(1:dimmax, 1:dimmax, f1, col=grey.colors(255), xaxt = 'n', yaxt = 'n')
      text(8, 5, col="white", cex=1.2, categories[fashion_train[i, 1]+1])
  }
  
}
```

Let's do another sanity test to make sure the function we created, `vizTrain` works as expected. Can you modify the code below to plot the first 36 digits?

by using the function above we can plot 36(any number of row) image.
```{r}
vizTrain(fashion_train[1:36,])
```

now by using mxnet, we will assemble a network and tune the parameter, we have to make sure the output layer have 10 unit because we have 10 categories. we will be using softMax in the last layer for this model.

```{r}
# notice how our layers are fully-connected and cascading
library(mxnet)
f1.data  <- mx.symbol.Variable("data") 

f1.fc1 <- mx.symbol.FullyConnected(f1.data, name="fc1", num_hidden=128)
f1.act1 <- mx.symbol.Activation(f1.fc1, name="activation1", act_type="relu")

f1.fc2 <- mx.symbol.FullyConnected(f1.act1, name="fc2", num_hidden=64)
f1.act2 <- mx.symbol.Activation(f1.fc2, name="activation2", act_type="relu")

f1.fc3 <- mx.symbol.FullyConnected(f1.act2, name="fc3", num_hidden=10)
f1.softmax <- mx.symbol.SoftmaxOutput(f1.fc3, name="softMax")
```

So we have a neural network created using the `mxnet` specification model, 
`data --> 128 units ReLU --> 64 units ReLU --> 10 units output softMax`

Before we build the model, we need to convert the data into matrix and prepare them.
```{r}
train <- data.matrix(fashion_train)
test <- data.matrix(fashion_test)

train_x <- train[,-1]
train_y <- train[,1] 
test_x <- test[,-1]

train_x <- t(train_x/255)
test_x <- t(test_x/255)
```

```{r}
dim(test_x)
```

To create a MXNet feedforward neural network, we'll pass in the symbolic network specification we created above, our X (input) and y (output). Most of the other variables are optional and have sensible default values. `num.round`, for example by default uses 10: that's how we specify the number of iterations over training data to train the model. I've increased this value to 40; 

`array.layout` is set to `auto` by default. For a matrix we use `rowmajor` when our dimensions are `c(example, features)` and `colmajor` when they are `c(features, examples)`. When it's `auto`, then it will try to auto-detect the layout by matching the feature size. We also specified "accuracy" as our performance metric, and finally we specified a callback to log the time our neural network uses: 

now we can create our neural network model and we will check how long it takes to train this model.
```{r}
library(mxnet)
log <- mx.metric.logger$new()
startime <- proc.time() 
mx.set.seed(0)

f1 <- mx.model.FeedForward.create(f1.softmax,  #the network configuration made above
                                     X = train_x, #input (predictors),
                                     y = train_y, #the labels
                                     ctx = mx.cpu(),
                                     num.round = 60,  # 10 get us ~0.93 accuracy
                                     array.batch.size = 80,
                                     momentum = 0.95,
                                     array.layout="colmajor",
                                     learning.rate = 0.003,
                                     eval.metric = mx.metric.accuracy,
                                     epoch.end.callback = mx.callback.log.train.metric(1,log)
)
print(paste("Training took:", round((proc.time() - startime)[3],2),"seconds"))
```

the accuracy of the train model is 94.85%, now we can plot the accuracy for each iteration.

```{r}
plot(log$train, type="l", xlab="Iteration", ylab="Accuracy")
```

now we can start make the prediction.

```{r}
f1_preds <- predict(f1, test_x, array.layout = "colmajor")
t(round(f1_preds[,1:5], 2))
```

The predictions is in probabilities, we can change them to show only the max value of all prediction.

```{r}
f1_preds_result <- max.col(t(f1_preds))
f1_preds_result[1:10]
```

now we can plot the picture with the prediction.
```{r}
plotResults <- function(images, preds){

  x <- ceiling(sqrt(length(images)))
  par(mfrow=c(x,x), mar=c(.1,.1,.1,.1))
  
  for (i in images){
    m <- matrix(test[i,-1], nrow=28, byrow=TRUE)
    m <- apply(m, 2, rev)
    image(t(m), col=grey.colors(255), axes=FALSE)
    text(0.24,0.1,col="red", cex=1.2, categories[preds[i]])
  }

}
```

```{r}
plotResults(1:49, f1_preds_result)
```

from the images above, we can see that most of our prediction is correct. we know the label of the test set, now we can make a confusion matrix to see how accurate this model for the test set.

```{r}
cm <- table("prediction" = (f1_preds_result-1), "actual" = test[,1])
cm
```
we can calculate the accuracy for the testset by summing all the correct prediction and divide it with the number of the testset

```{r}
sum(886,982,818,847,792,935,705,873,966,979)/10000
```
We got 87.83%

